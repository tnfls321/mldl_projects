{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단일 알고리즘 적용\n",
    "\n",
    "- 1~4단계, 6단계 생략\n",
    "- 5단계만 수행하고, 앞의 단계는 간략하게 처리한다.\n",
    "- 데이터는 제공하는 데이터중 유방암 진단 데이터를 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈가져오기\n",
    "from sklearn.svm import SVC    # 지도학습>분류\n",
    "from sklearn.datasets import load_breast_cancer         # 제공데이터(연습을 위해 제공)\n",
    "from sklearn.model_selection import train_test_split    # 훈련/테스트데이터 나눔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 로드\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn.utils.Bunch -> sklearn의 제공데이터의 자료형\n",
    "# cancer\n",
    "type(cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30),\n",
       " array([[1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,\n",
       "         3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,\n",
       "         8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,\n",
       "         3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,\n",
       "         1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01]]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터의 볼륨 살펴보기\n",
    "# 암을 진단하는데 체크 포인트가 30개이다.(특성)\n",
    "cancer['data'].shape, cancer['data'][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답 => 암이다/아니다 => 0:악성/1:양성 => 학습효과가 좋음\n",
    "cancer['target'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'), 30)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특성\n",
    "cancer['feature_names'], len(cancer['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#악성, 양성\n",
    "cancer['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 분류\n",
    "# 75:25 = 훈련:테스트\n",
    "# seed를 고정하면 => 난수가 일정하게 발생 => 실험치가 똑같다(데이터의 섞임을 동일하게 구성)\n",
    "# => 알고리즘, 기타 방법들로 성능을 항상 비교할 수 있다.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data,      # 독립변수, 개별적인 30개의 변수(특성)\n",
    "    cancer.target,    # 종속변수, 답안(레이블, 답, 클래스), 0 or 1(이진데이터, 범주형변수)\n",
    "    random_state=0,   # 난수를 고정 => 언제 돌려도 항상 같은 순서로 난수가 발생(씨드고정)\n",
    "    test_size=0.25    # 25%가 테스트 데이터이다 (생략해도 동일, 기본이 25%)    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 143, 426, 143, 429)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 분류된 데이터의 개수를 확인해서 75:25인제 치크\n",
    "len(X_train), len(X_test),len(y_train),len(y_test), len(y_test)*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 30), (143, 30))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 알고리즘 생성\n",
    "clf = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "predict = clf.predict( X_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6293706293706294"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score( y_test, predict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6293706293706294"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 및 평가 동시 수행\n",
    "clf.score( X_test, y_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 리뷰\n",
    "\n",
    "- 정확도가 많이 떨어진다 -> 성능 향상이 필요\n",
    "- 데이터를 더 많이 확보할 수 있는가?\n",
    "- 데이터의 품질을 높이는 쪽으로 접근할 것인가?\n",
    "- 알고리즘의 하이퍼파라미터 튜닝을 수행할 것인가?\n",
    "- 파이프라인을 구축하여 품질을 더 높이고, 알고리즘을 교차로 비교할 것인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,\n",
       "        3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,\n",
       "        8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,\n",
       "        3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,\n",
       "        1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 들여다 보니 값의 편차가 크다 (통계 기초)\n",
    "# 비지도 학습의 전처리기를 이용하여 스케일을 수행하여 데이터의 범위를 좁히겠다.(API)\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 품질을 높이기 위해서\n",
    "# 훈련 데이터를 넣어서 스케일링 처리\n",
    "scaler = MinMaxScaler().fit( X_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23044157, 0.32157676, 0.21940433, 0.12267232, 0.33767785,\n",
       "        0.12684063, 0.06298032, 0.11332008, 0.41161616, 0.15143218,\n",
       "        0.03458265, 0.19353412, 0.02247562, 0.0124343 , 0.27210066,\n",
       "        0.12240273, 0.03565657, 0.1624929 , 0.18735302, 0.03072012,\n",
       "        0.18249733, 0.36593817, 0.16903232, 0.081744  , 0.43406194,\n",
       "        0.14408515, 0.10511182, 0.31484671, 0.30277942, 0.09858323]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 변환 처리\n",
    "X_train_scaler = scaler.transform( X_train )\n",
    "\n",
    "# 최소값을 0, 최대값을 1로 두고 0-1사이로 정규화를 수행한 것과 유사하다.\n",
    "# 학습 효과를 극대화 하겠다.\n",
    "X_train_scaler[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 알고리즘 생성\n",
    "clf2 = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련\n",
    "clf2.fit(X_train_scaler, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.951048951048951"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 및 평가\n",
    "# 테스트 데이터를 동일학 ㅔ스케일링 처리 후 예측시킨다.\n",
    "clf2.score( scaler.transform(X_test), y_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 튜닝\n",
    "- 머신러닝 모형이 완성되고 나서, 매개변수(parameter)를 통해서 예측 성능을 더 극대화 할 수 있다.\n",
    "- 도구\n",
    "    - vaildation_curve(함수) : 단일 하이퍼파라미터 최적화 도구   \n",
    "    - GridSearchCV(클래스) : 그리드를 이용하여 복수 하이퍼파라미터 최적화 수행 클래스\n",
    "    - ParameterGrid : 복수 하이퍼파라미터 최적화 수행 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 알고리즘별 매개변수 최적화 항목\n",
    "\n",
    "<img src = './table/매개변수.png' width='400'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC 알고리즘에 대한 파라미터 범주를 설정\n",
    "# C, gamma만 적용해본다.\n",
    "# 케이스 수는 -> 매개변수 개수 * 값의 범주 수 *...\n",
    "param_grid = {\n",
    "    \"C\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'gamma':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그리드 생성\n",
    "# cv : 폴드의 단위를 기록(세트의 수)\n",
    "# cv=5 => 5세트로 훈련데이터를 구성한다. 그 중에 한개가 검증용 데이터이다.\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./table/cro.png' width='700'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 => 매개변수 조합에 의해서 각각 교차로 학습 수행\n",
    "grid.fit( X_train_scaler, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9812206572769953"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 1}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적의 매개변수\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972027972027972"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 및 평가\n",
    "grid.score( scaler.transform( X_test ), y_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 현재 훈련데이터의 검증 데이터의 적용상황\n",
    "- 스케일링 작업간에 검증 폴드가 영향을 미쳐서 정확도에 부정확성을 키울 수 있다\n",
    "<img src='./table/cro.png' width='700'>\n",
    "- 개선 상황\n",
    "- 파이프라인을 구성하여 이 부분을 개선한다.\n",
    "<img src='./table/cro2.png' width='700'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이프라인 구축\n",
    "\n",
    "- 검증 폴드의 전처리 적용시 학습 데이터에 영향을 미치는 문제(위에서 언급) 해결\n",
    "- 여러 알고리즘을 비교\n",
    "- 전체 공정을 시퀀스로 연결하여 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인 구축 방법은 2가지\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "# 알고리즘 추가\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다시 데이터 분류\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data,      # 독립변수, 개별적인 30개의 변수(특성)\n",
    "    cancer.target,    # 종속변수, 답안(레이블, 답, 클래스), 0 or 1(이진데이터, 범주형변수)\n",
    "    random_state=0,   # 난수를 고정 => 언제 돌려도 항상 같은 순서로 난수가 발생(씨드고정)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 30), (143, 30))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler', <class 'sklearn.preprocessing.data.MinMaxScaler'>),\n",
       "                ('classigier',\n",
       "                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3,\n",
       "                     gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파이프라인 구축 예\n",
    "# case 1 : 표준방법, 작업 순서를 나열하고 이를 각각 부여\n",
    "pipe_std = Pipeline( [ \n",
    "    ('scaler', MinMaxScaler),\n",
    "    ('classigier', SVC() )\n",
    "] )\n",
    "pipe_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                ('svc',\n",
       "                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3,\n",
       "                     gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# case 2 : 간소화 방법, 이름을 자동으로 생성(소문자로)\n",
    "pipe_sim = make_pipeline( MinMaxScaler(), SVC() )\n",
    "pipe_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 파이프라인 구축\n",
    "# 경험적으로, 선택 시트를 같이 검토하여 후보가 유력한 알고리즘과 전처리기를 배치\n",
    "pipe = Pipeline( [\n",
    "    ('preprocessing', StandardScaler()),\n",
    "    ('classifier', SVC() )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 하이퍼파라미터 튜닝\n",
    "# 경험적으로, 선택 시트를 같이 검토하여 대상이 되는 알고리즘, 전처리기 등등 조합\n",
    "# 파라미터 리스트를 배치\n",
    "param_grid = [\n",
    "    {\n",
    "        'classifier':[SVC() ],\n",
    "        'preprocessing':[StandardScaler(), MinMaxScaler() ],\n",
    "        # 이름__파라미터명 => 해당 알고리즘에 적용되는 파라미터이다.\n",
    "        'classifier__C':[0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'classifier__gamma':[0.001, 0.01, 0.1, 1, 10, 100]\n",
    "    },\n",
    "    {\n",
    "        'classifier':[RandomForestClassifier(n_estimators=100) ],\n",
    "        'preprocessing':[None],\n",
    "        'classifier__max_features':[1,2,3]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결합 ( 파이프라인, 하이퍼파라미터 튜닝 )\n",
    "grid = GridSearchCV( pipe, param_grid, cv=5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocessing',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('classifier',\n",
       "                                        SVC(C=1.0, cache_size=200,\n",
       "                                            class_weight=None, coef0=0.0,\n",
       "                                            decision_function_shape='ovr',\n",
       "                                            degree=3, gamma='auto_deprecated',\n",
       "                                            kernel='rbf', max_iter=-1,\n",
       "                                            probability=False,\n",
       "                                            random_state=Non...\n",
       "                                                                min_impurity_decrease=0.0,\n",
       "                                                                min_impurity_split=None,\n",
       "                                                                min_samples_leaf=1,\n",
       "                                                                min_samples_split=2,\n",
       "                                                                min_weight_fraction_leaf=0.0,\n",
       "                                                                n_estimators=100,\n",
       "                                                                n_jobs=None,\n",
       "                                                                oob_score=False,\n",
       "                                                                random_state=None,\n",
       "                                                                verbose=0,\n",
       "                                                                warm_start=False)],\n",
       "                          'classifier__max_features': [1, 2, 3],\n",
       "                          'preprocessing': [None]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련\n",
    "grid.fit( X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9859154929577465"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적 점수\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False),\n",
       " 'classifier__C': 10,\n",
       " 'classifier__gamma': 0.01,\n",
       " 'preprocessing': StandardScaler(copy=True, with_mean=True, with_std=True)}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9790209790209791"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
